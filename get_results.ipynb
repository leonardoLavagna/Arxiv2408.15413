{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVALwvXkozSI"
   },
   "source": [
    "# Article..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFiQS-lToy65"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4_xXNSanX6V"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/NesyaLab/qaoa/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LybW0n0dnimP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/main/Desktop/qaoa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "679axBjquUmQ"
   },
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2Fdoh0_Upj1E"
   },
   "outputs": [],
   "source": [
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ztMHfEvkoJkp"
   },
   "outputs": [],
   "source": [
    "from classes import Problems as P\n",
    "from classes import Qaoa as Q\n",
    "from functions import qaoa_utilities as qaoa_utils\n",
    "from functions import maxcut_utilities as mcut_utils\n",
    "from functions import qaoa_optimizers as optims\n",
    "from functions import symmetry_utilities as sym_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yZyXaAF7oSce"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3dhN7_1ownB"
   },
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "d4v9wrBAonNk"
   },
   "outputs": [],
   "source": [
    "graphs = []\n",
    "for i in range(num_graphs):\n",
    "    graph_path =  \"/graph_\"+str(i)+\".nx\"\n",
    "    with open(\"data/graph_\"+str(i)+\".nx\", 'rb') as f:\n",
    "        g = pickle.load(f)\n",
    "    graphs.append(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YIPPApbrfva"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bz2Ftqy1qXjN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: results: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir results\n",
    "results_path = \"/results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9spvD0Rrq1i"
   },
   "source": [
    "### Brute force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tiTJVIctrsnj"
   },
   "outputs": [],
   "source": [
    "bfs = [0]*len(graphs)\n",
    "idx = 0\n",
    "for graph in graphs:\n",
    "    bfs[idx] = mcut_utils.compute_max_cut_exactly(graph)\n",
    "    idx += 1\n",
    "\n",
    "with open(\"results/brute_force_solution\", 'wb') as file:\n",
    "    pickle.dump(bfs, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDUtRYA7p06o"
   },
   "source": [
    "### Qaoa vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dr3Ixrv8pqJ9"
   },
   "outputs": [],
   "source": [
    "for seed_ in range(seed, seed+3):\n",
    "    for layer in range(1,p+1):\n",
    "        betas = qaoa_utils.generate_parameters(n=layer, k=1, seed=seed_)\n",
    "        gammas = qaoa_utils.generate_parameters(n=layer, k=2, seed=seed_)\n",
    "        for idx in range(num_graphs):\n",
    "            name = \"qaoa_vanilla_graph_\" + str(idx) + \"_p_\" + str(layer) + \"_seed_\" + str(seed_)\n",
    "            G = graphs[idx]\n",
    "            qaoa = Q.Qaoa(p=layer, G=G, betas=betas, gammas=gammas, mixer=mixer, seed=seed_, verbose=verbose)\n",
    "            x, f = optims.simple_optimization(qaoa, method=method, seed=seed_, verbose=verbose)\n",
    "            AR = -f/bfs[idx]\n",
    "            with open(\"results/\" + name, 'wb') as file:\n",
    "                pickle.dump((x,f,AR), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Rmx4VoYqy_-"
   },
   "source": [
    "### QAOA extended with one \"shadow\" node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HqIGABtjqyIP"
   },
   "outputs": [],
   "source": [
    "for seed_ in range(seed, seed+3):\n",
    "    for layer in range(1,p+1):\n",
    "        betas = qaoa_utils.generate_parameters(n=layer, k=1, seed=seed_)\n",
    "        gammas = qaoa_utils.generate_parameters(n=layer, k=2, seed=seed_)\n",
    "        for idx in range(num_graphs):\n",
    "            name = \"qaoa_extended_1_graph_\" + str(idx) + \"_p_\" + str(layer) + \"_seed_\" + str(seed_)\n",
    "            G = graphs[idx]\n",
    "            N = graphs[idx].get_number_of_nodes()\n",
    "            G_ = graphs[idx].get_graph().copy()\n",
    "            G_.add_node(N)\n",
    "            extended_graph_instance = P.Problems(p_type=\"custom\", G=G_)\n",
    "            qaoa = Q.Qaoa(p=layer, G=extended_graph_instance, betas=betas, gammas=gammas, mixer=mixer, seed=seed_, verbose=verbose)\n",
    "            x, f = optims.simple_optimization(qaoa, method=method, seed=seed_, verbose=verbose)\n",
    "            AR = -f/bfs[idx]\n",
    "            with open(\"results/\" + name, 'wb') as file:\n",
    "                pickle.dump((x,f,AR), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4O1t3Tkq7L2"
   },
   "source": [
    "### QAOA extended with two \"shadow\" nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RuSvnpAIqyAi"
   },
   "outputs": [],
   "source": [
    "for seed_ in range(seed, seed+3):\n",
    "    for layer in range(1,p+1):\n",
    "        betas = qaoa_utils.generate_parameters(n=layer, k=1, seed=seed_)\n",
    "        gammas = qaoa_utils.generate_parameters(n=layer, k=2, seed=seed_)\n",
    "        for idx in range(num_graphs):\n",
    "            name = \"qaoa_extended_2_graph_\" + str(idx) + \"_p_\" + str(layer) + \"_seed_\" + str(seed_)\n",
    "            G = graphs[idx]\n",
    "            N = graphs[idx].get_number_of_nodes()\n",
    "            G_ = graphs[idx].get_graph().copy()\n",
    "            G_.add_node(N)\n",
    "            G_.add_node(N+1)\n",
    "            extended_graph_instance = P.Problems(p_type=\"custom\", G=G_)\n",
    "            qaoa = Q.Qaoa(p=layer, G=extended_graph_instance, betas=betas, gammas=gammas, mixer=mixer, seed=seed_, verbose=verbose)\n",
    "            x, f = optims.simple_optimization(qaoa, method=method, seed=seed_, verbose=verbose)\n",
    "            AR = -f/bfs[idx]\n",
    "            with open(\"results/\" + name, 'wb') as file:\n",
    "                pickle.dump((x,f,AR), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ii7pYflarCR2"
   },
   "source": [
    "### QAOA extended with one pendent edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "547v59T-pueu"
   },
   "outputs": [],
   "source": [
    "for seed_ in range(seed, seed+3):\n",
    "    for layer in range(1,p+1):\n",
    "        betas = qaoa_utils.generate_parameters(n=layer, k=1, seed=seed_)\n",
    "        gammas = qaoa_utils.generate_parameters(n=layer, k=2, seed=seed_)\n",
    "        for idx in range(num_graphs):\n",
    "            name = \"qaoa_extended_3_graph_\" + str(idx) + \"_p_\" + str(layer) + \"_seed_\" + str(seed_)\n",
    "            G = graphs[idx]\n",
    "            N = graphs[idx].get_number_of_nodes()\n",
    "            G_ = graphs[idx].get_graph().copy()\n",
    "            G_.add_node(N)\n",
    "            u = list(G_.nodes())[N]\n",
    "            v = list(G_.nodes())[random.randint(0,N-1)]\n",
    "            G_.add_edge(u,v)\n",
    "            extended_graph_instance = P.Problems(p_type=\"custom\", G=G_)\n",
    "            qaoa = Q.Qaoa(p=layer, G=extended_graph_instance, betas=betas, gammas=gammas, mixer=mixer, seed=seed_, verbose=verbose)\n",
    "            x, _ = optims.simple_optimization(qaoa, method=method, seed=seed_, verbose=verbose)\n",
    "            qaoa = Q.Qaoa(p=layer, G=graphs[idx], betas=x[:layer], gammas=x[layer:], mixer=mixer, seed=seed_, verbose=verbose)\n",
    "            _, f = optims.simple_optimization(qaoa, method=method, seed=seed_, verbose=verbose)\n",
    "            AR = -f/bfs[idx]\n",
    "            with open(\"results/\" + name, 'wb') as file:\n",
    "                pickle.dump((x,f,AR), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7u_a_zJsrGrO"
   },
   "source": [
    "### QAOA reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2uML-9dNrCtG"
   },
   "outputs": [],
   "source": [
    "for seed_ in range(seed, seed+3):\n",
    "    for layer in range(1,p+1):\n",
    "        betas = qaoa_utils.generate_parameters(n=layer, k=1, seed=seed_)\n",
    "        gammas = qaoa_utils.generate_parameters(n=layer, k=2, seed=seed_)\n",
    "        for idx in range(num_graphs):\n",
    "            name = \"qaoa_reduced_graph_\" + str(idx) + \"_p_\" + str(layer) + \"_seed_\" + str(seed_)\n",
    "            G = graphs[idx]\n",
    "            G_ = graphs[idx].get_graph().copy()\n",
    "            G_prime = P.Problems(p_type=\"custom\", G=G_)\n",
    "            opt = [0]\n",
    "            for edge in G_prime.get_edges():\n",
    "                G_reduced = G_prime.get_graph().copy()\n",
    "                G_reduced.remove_edges_from([edge])\n",
    "                reduced_graph_instance = P.Problems(p_type=\"custom\", G=G_reduced)\n",
    "                qaoa = Q.Qaoa(p=layer, G=G, betas=betas, gammas=gammas, mixer=mixer, seed=seed_, verbose=verbose)\n",
    "                x, f = optims.simple_optimization(qaoa, method=method, seed=seed_, verbose=verbose)\n",
    "                AR = -f/bfs[idx]\n",
    "                opt.append(AR)\n",
    "            with open(\"results/\" + name, 'wb') as file:\n",
    "                pickle.dump((x,f,max(opt)), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytZsqF_ksDpx"
   },
   "source": [
    "### Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XY8PcqccsE9e"
   },
   "outputs": [],
   "source": [
    "# CALCULATING SPECTRAL RADIUS METRIC FOR EACH GRAPH\n",
    "\n",
    "idx = 0\n",
    "metric = {}\n",
    "spectral_radii = []\n",
    "avg_degrees = []\n",
    "for graph in graphs:\n",
    "    # The max eigenvalue is real\n",
    "    rho = float(max(graph.get_adjacency_spectrum()))\n",
    "    D = np.diag(np.sum(graph.get_adjacency_matrix(), axis=1))\n",
    "    spectral_radii.append(rho)\n",
    "    avg_degrees.append(int(np.sum(D)/D.shape[0]))\n",
    "    metric[idx] = [avg_degrees[idx] / spectral_radii[idx]]\n",
    "    idx += 1\n",
    "with open(\"results/spectral_radii\", 'wb') as file:\n",
    "    pickle.dump(spectral_radii, file)\n",
    "with open(\"results/spectral_metric_unperturbed\", 'wb') as file:\n",
    "    pickle.dump(metric, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KYSw3LcesLdG"
   },
   "outputs": [],
   "source": [
    "# CALCULATING SPECTRAL RADIUS METRIC FOR EACH GRAPH PERTURBATION\n",
    "\n",
    "# One shadow node\n",
    "idx = 0\n",
    "metric_shadow1 = {}\n",
    "spectral_radii_shadow1 = []\n",
    "avg_degrees_shadow1 = []\n",
    "for graph in graphs:\n",
    "    N = graph.get_number_of_nodes()\n",
    "    G = graph.get_graph().copy()\n",
    "    G.add_node(N)\n",
    "    instance = P.Problems(p_type=\"custom\", G=G)\n",
    "    rho = float(max(instance.get_adjacency_spectrum()))\n",
    "    D = np.diag(np.sum(instance.get_adjacency_matrix(), axis=1))\n",
    "    spectral_radii_shadow1.append(rho)\n",
    "    avg_degrees_shadow1.append(int(np.sum(D)/D.shape[0]))\n",
    "    metric_shadow1[idx] = [avg_degrees_shadow1[idx] / spectral_radii_shadow1[idx]]\n",
    "    idx += 1\n",
    "with open(\"results/spectral_radii_shadow1\", 'wb') as file:\n",
    "    pickle.dump(spectral_radii_shadow1, file)\n",
    "with open(\"results/spectral_metric_shadow1\", 'wb') as file:\n",
    "    pickle.dump(metric_shadow1, file)\n",
    "\n",
    "# Two shadow nodes\n",
    "idx = 0\n",
    "metric_shadow2 = {}\n",
    "spectral_radii_shadow2 = []\n",
    "avg_degrees_shadow2 = []\n",
    "for graph in graphs:\n",
    "    N = graph.get_number_of_nodes()\n",
    "    G = graph.get_graph().copy()\n",
    "    G.add_node(N)\n",
    "    G.add_node(N+1)\n",
    "    instance = P.Problems(p_type=\"custom\", G=G)\n",
    "    rho = float(max(instance.get_adjacency_spectrum()))\n",
    "    D = np.diag(np.sum(instance.get_adjacency_matrix(), axis=1))\n",
    "    spectral_radii_shadow2.append(rho)\n",
    "    avg_degrees_shadow2.append(int(np.sum(D)/D.shape[0]))\n",
    "    metric_shadow2[idx] = [avg_degrees_shadow2[idx] / spectral_radii_shadow2[idx]]\n",
    "    idx += 1\n",
    "with open(\"results/spectral_radii_shadow2\", 'wb') as file:\n",
    "    pickle.dump(spectral_radii_shadow2, file)\n",
    "with open(\"results/spectral_metric_shadow2\", 'wb') as file:\n",
    "    pickle.dump(metric_shadow2, file)\n",
    "\n",
    "\n",
    "# One pendent edge\n",
    "idx = 0\n",
    "metric_pendent = {}\n",
    "spectral_radii_pendent = []\n",
    "avg_degrees_pendent = []\n",
    "for graph in graphs:\n",
    "    N = graph.get_number_of_nodes()\n",
    "    G = graph.get_graph().copy()\n",
    "    G.add_node(N)\n",
    "    u = list(G.nodes())[N]\n",
    "    v = list(G.nodes())[random.randint(0,N-2)]\n",
    "    G.add_edge(u,v)\n",
    "    instance = P.Problems(p_type=\"custom\", G=G)\n",
    "    rho = float(max(instance.get_adjacency_spectrum()))\n",
    "    D = np.diag(np.sum(instance.get_adjacency_matrix(), axis=1))\n",
    "    spectral_radii_pendent.append(rho)\n",
    "    avg_degrees_pendent.append(int(np.sum(D)/D.shape[0]))\n",
    "    metric_pendent[idx] = [avg_degrees_pendent[idx] / spectral_radii_pendent[idx]]\n",
    "    idx += 1\n",
    "with open(\"results/spectral_radii_pendent\", 'wb') as file:\n",
    "    pickle.dump(spectral_radii_pendent, file)\n",
    "with open(\"results/spectral_metric_pendent\", 'wb') as file:\n",
    "    pickle.dump(metric_pendent, file)\n",
    "\n",
    "# One deleted edge\n",
    "idx = 0\n",
    "metric_deleted = {}\n",
    "spectral_radii_deleted = {}\n",
    "avg_degrees_deleted = {}\n",
    "for graph in graphs:\n",
    "    N = graph.get_number_of_nodes()\n",
    "    G = graph.get_graph().copy()\n",
    "    G_ = P.Problems(p_type=\"custom\", G=G)\n",
    "    metric_deleted_vec = []\n",
    "    avg_degrees_deleted_vec = []\n",
    "    spectral_radii_deleted_vec = []\n",
    "    for edge in G_.get_edges():\n",
    "        G_reduced = G_.get_graph().copy()\n",
    "        G_reduced.remove_edges_from([edge])\n",
    "        instance = P.Problems(p_type=\"custom\", G=G_reduced)\n",
    "        rho = float(max(instance.get_adjacency_spectrum()))\n",
    "        D = np.diag(np.sum(instance.get_adjacency_matrix(), axis=1))\n",
    "        spectral_radii_deleted_vec.append(rho)\n",
    "        avg_degrees_deleted_vec.append(int(np.sum(D)/D.shape[0]))\n",
    "    spectral_radii_deleted[idx] = max(spectral_radii_deleted_vec)\n",
    "    avg_degrees_deleted[idx] = max(avg_degrees_deleted_vec)\n",
    "    metric_deleted[idx] = [avg_degrees_deleted[idx] / spectral_radii_deleted[idx]]\n",
    "    idx += 1\n",
    "with open(\"results/spectral_radii_deleted\", 'wb') as file:\n",
    "    pickle.dump(spectral_radii_deleted, file)\n",
    "with open(\"results/spectral_metric_deleted\", 'wb') as file:\n",
    "    pickle.dump(metric_deleted, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvURQT9BsPUh"
   },
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "print(metric, \"\\n\")\n",
    "print(metric_shadow1, \"\\n\")\n",
    "print(metric_shadow2, \"\\n\")\n",
    "print(metric_pendent, \"\\n\")\n",
    "print(metric_deleted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poCyqtNssbgJ"
   },
   "source": [
    "### Symmetries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AUolVxrpscWk"
   },
   "outputs": [],
   "source": [
    "# CALCULATING |AUT(G)| FOR EACH GRAPH\n",
    "\n",
    "num_symmetries = []\n",
    "generating_symmetries = []\n",
    "for graph in graphs:\n",
    "    adjacency_dict = graph.get_adjacency_dict()\n",
    "    num_automorphisms = sym_utils.get_number_of_automorphisms(G=graph, adjacency_dict=adjacency_dict)\n",
    "    generators = sym_utils.get_symmetry_generators(G=graph, adjacency_dict=adjacency_dict)\n",
    "    num_symmetries.append(num_automorphisms)\n",
    "    generating_symmetries.append(generators)\n",
    "with open(\"results/aut_G\", 'wb') as file:\n",
    "      pickle.dump((num_symmetries,generating_symmetries), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUXQ0ZylsdvN"
   },
   "outputs": [],
   "source": [
    "# CALCULATING |AUT(G')| FOR EACH GRAPH PERTURBATION\n",
    "\n",
    "# One shadow node\n",
    "num_symmetries_shadow1 = []\n",
    "generating_symmetries_shadow1 = []\n",
    "for graph in graphs:\n",
    "    N = graph.get_number_of_nodes()\n",
    "    G = graph.get_graph().copy()\n",
    "    G.add_node(N)\n",
    "    instance = P.Problems(p_type=\"custom\", G=G)\n",
    "    adjacency_dict = instance.get_adjacency_dict()\n",
    "    num_automorphisms = sym_utils.get_number_of_automorphisms(G=instance, adjacency_dict=adjacency_dict)\n",
    "    generators = sym_utils.get_symmetry_generators(G=instance, adjacency_dict=adjacency_dict)\n",
    "    num_symmetries_shadow1.append(num_automorphisms)\n",
    "    generating_symmetries_shadow1.append(generators)\n",
    "\n",
    "\n",
    "# Two shadow nodes\n",
    "num_symmetries_shadow2 = []\n",
    "generating_symmetries_shadow2 = []\n",
    "for graph in graphs:\n",
    "    N = graph.get_number_of_nodes()\n",
    "    G = graph.get_graph().copy()\n",
    "    G.add_node(N)\n",
    "    G.add_node(N+1)\n",
    "    instance = P.Problems(p_type=\"custom\", G=G)\n",
    "    adjacency_dict = instance.get_adjacency_dict()\n",
    "    num_automorphisms = sym_utils.get_number_of_automorphisms(G=instance, adjacency_dict=adjacency_dict)\n",
    "    generators = sym_utils.get_symmetry_generators(G=instance, adjacency_dict=adjacency_dict)\n",
    "    num_symmetries_shadow2.append(num_automorphisms)\n",
    "    generating_symmetries_shadow2.append(generators)\n",
    "\n",
    "\n",
    "# One pendent edge\n",
    "num_symmetries_pendent = []\n",
    "generating_symmetries_pendent = []\n",
    "for graph in graphs:\n",
    "    N = graph.get_number_of_nodes()\n",
    "    G = graph.get_graph().copy()\n",
    "    G.add_node(N)\n",
    "    u = list(G.nodes())[N]\n",
    "    v = list(G.nodes())[random.randint(0,N-2)]\n",
    "    G.add_edge(u,v)\n",
    "    instance = P.Problems(p_type=\"custom\", G=G)\n",
    "    adjacency_dict = instance.get_adjacency_dict()\n",
    "    num_automorphisms = sym_utils.get_number_of_automorphisms(G=instance, adjacency_dict=adjacency_dict)\n",
    "    generators = sym_utils.get_symmetry_generators(G=instance, adjacency_dict=adjacency_dict)\n",
    "    num_symmetries_pendent.append(num_automorphisms)\n",
    "    generating_symmetries_pendent.append(generators)\n",
    "\n",
    "\n",
    "# One deleted edge\n",
    "idx = 0\n",
    "num_symmetries_deleted = {}\n",
    "generating_symmetries_deleted= {}\n",
    "for graph in graphs:\n",
    "    N = graph.get_number_of_nodes()\n",
    "    G = graph.get_graph().copy()\n",
    "    G_ = P.Problems(p_type=\"custom\", G=G)\n",
    "    num_symmetries_deleted_vec = []\n",
    "    generating_symmetries_deleted_vec = []\n",
    "    for edge in G_.get_edges():\n",
    "        G_reduced = G_.get_graph().copy()\n",
    "        G_reduced.remove_edges_from([edge])\n",
    "        instance = P.Problems(p_type=\"custom\", G=G_reduced)\n",
    "        adjacency_dict = instance.get_adjacency_dict()\n",
    "        num_automorphisms = sym_utils.get_number_of_automorphisms(G=instance, adjacency_dict=adjacency_dict)\n",
    "        generators = sym_utils.get_symmetry_generators(G=instance, adjacency_dict=adjacency_dict)\n",
    "        num_symmetries_deleted_vec.append(num_automorphisms)\n",
    "        generating_symmetries_deleted_vec.append(generators)\n",
    "    num_symmetries_deleted[idx] = num_symmetries_deleted_vec\n",
    "    generating_symmetries_deleted[idx] = generating_symmetries_deleted_vec\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Si4PbhDysgZe"
   },
   "outputs": [],
   "source": [
    "# CHECK\n",
    "\n",
    "print(num_symmetries)\n",
    "print(num_symmetries_shadow1)\n",
    "print(num_symmetries_shadow2)\n",
    "print(num_symmetries_pendent)\n",
    "print(num_symmetries_deleted)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
